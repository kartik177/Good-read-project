{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Goodreads project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "w_jFJEqAvMrG",
        "outputId": "88e81ac7-df56-498b-f1fe-7278ea45fe0d"
      },
      "source": [
        "!pip install langdetect -q\n",
        "from langdetect import detect\n",
        "\n",
        "import string\n",
        "valid_chars=string.ascii_letters+string.digits+' '\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cufflinks as cf\n",
        "cf.go_offline()\n",
        "from collections import defaultdict\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def configure_plotly_browser_state():\n",
        "    #This function is required to see Plotly charts in colab. Call this function in every cell where a Plotly chart gets drawn.\n",
        "    import IPython\n",
        "    display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-1.43.1.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 9.4MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 8.0MB/s eta 0:00:01\r\u001b[K     |█▍                              | 40kB 7.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 51kB 3.0MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 3.3MB/s eta 0:00:01\r\u001b[K     |██▍                             | 71kB 3.4MB/s eta 0:00:01\r\u001b[K     |██▊                             | 81kB 3.6MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 102kB 3.8MB/s eta 0:00:01\r\u001b[K     |███▊                            | 112kB 3.8MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 3.8MB/s eta 0:00:01\r\u001b[K     |████▍                           | 133kB 3.8MB/s eta 0:00:01\r\u001b[K     |████▊                           | 143kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 163kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 174kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 194kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 204kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 225kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 235kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 256kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 266kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 286kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 296kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 317kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 327kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 348kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 358kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 378kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 389kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 409kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 419kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 440kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 450kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 471kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 481kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 501kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 512kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 532kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 542kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 563kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 573kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 593kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 604kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 624kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 634kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 645kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 655kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 665kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 675kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 686kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 696kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 706kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 716kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 727kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 737kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 747kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 757kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 768kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 778kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 788kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 798kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 808kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 819kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 829kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 839kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 849kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 860kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 870kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 880kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 890kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 901kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 911kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 921kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 931kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 942kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 952kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 962kB 3.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 972kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 983kB 3.8MB/s \n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "TjfYUvAOvpVC",
        "outputId": "3894ba72-90a9-427b-db1b-2041211cd8ce"
      },
      "source": [
        "!pip install kaggle --upgrade -q\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d1774a59-f1a6-4f0c-89d5-ffe7402e2ff6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d1774a59-f1a6-4f0c-89d5-ffe7402e2ff6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNocTNMVwgOv"
      },
      "source": [
        "book_data_train=pd.read_csv('train/book_data.csv')\n",
        "book_data_test=pd.read_csv('test/book_data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yw93IJxoxYpj"
      },
      "source": [
        "\n",
        "book_data_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5JXbiKzx7Ml"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from requests import get\n",
        "\n",
        "#Sometimes not including the header results in a failed response\n",
        "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "         'Referer': 'https://cssspritegenerator.com',\n",
        "         'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "         'Accept-Encoding': 'none',\n",
        "         'Accept-Language': 'en-US,en;q=0.8'}\n",
        "\n",
        "BASE_URL='https://www.goodreads.com'\n",
        "LIST_URL='https://www.goodreads.com/list/show/1.Best_Books_Ever'\n",
        "#LIST_URL='https://www.goodreads.com/list/best_of_year/2018?id=119307.Best_books_of_2018'\n",
        "\n",
        "books={'URL':[]}\n",
        "\n",
        "#the no. of pages this list has\n",
        "num_pages=557\n",
        "\n",
        "for i in range(1, num_pages):\n",
        "  #time.sleep(120) #make sure you give enough time between page loads to not avoid server overload\n",
        "  print(f'Reading page {i}')\n",
        "  list_page_url=f'{LIST_URL}&page={i}'\n",
        "  list_page=get(list_page_url, headers=hdr)\n",
        "  list_soup = BeautifulSoup(list_page.content, 'html.parser')\n",
        "  book_table=list_soup.find('table', attrs={'class':'tableList js-dataTooltip'})\n",
        "  rows=book_table.find_all('tr')\n",
        "  books['URL']+=[BASE_URL+r.find('a', attrs={'class':'bookTitle'}).attrs['href'] for r in rows]\n",
        "\n",
        "books_df=pd.DataFrame.from_dict(books)\n",
        "books_df.to_csv('books.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YLgbEhpyAVG"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "from requests import get\n",
        "\n",
        "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "         'Referer': 'https://cssspritegenerator.com',\n",
        "         'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "         'Accept-Encoding': 'none',\n",
        "         'Accept-Language': 'en-US,en;q=0.8'}\n",
        "\n",
        "if not os.path.exists('book_data.csv'):\n",
        "  book_data=pd.DataFrame(columns=[\n",
        "    'image_url',\n",
        "    'book_title',\n",
        "    'book_authors',\n",
        "    'book_rating',\n",
        "    'book_rating_count',\n",
        "    'book_review_count',\n",
        "    'book_desc',\n",
        "    'book_format',\n",
        "    'book_edition',\n",
        "    'book_pages',\n",
        "    'book_isbn',\n",
        "    'genres'\n",
        "  ])\n",
        "\n",
        "  book_data.to_csv('book_data.csv')\n",
        "\n",
        "books=pd.read_csv('books.csv')\n",
        "book_data=pd.read_csv('book_data.csv')\n",
        "\n",
        "book_rows=[]\n",
        "save_every=10\n",
        "\n",
        "for i in range(len(book_data), len(books)):\n",
        "    time.sleep(60)\n",
        "    try:\n",
        "        book_URL=books.at[i, 'URL']\n",
        "        book_page=get(book_URL)\n",
        "        book_soup=BeautifulSoup(book_page.content, 'html.parser')\n",
        "\n",
        "        book=dict()\n",
        "\n",
        "        #Save the URL of the image of the book cover to be downloaded later\n",
        "        image_url=book_soup.find('img', attrs={'id':'coverImage'})\n",
        "        if image_url:\n",
        "            book['image_url']=image_url.attrs['src']\n",
        "        else:\n",
        "            book['image_url']=''\n",
        "\n",
        "        #Title of the book\n",
        "        book_title=book_soup.find('h1', attrs={'id':'bookTitle'})\n",
        "        if book_title:\n",
        "            book['book_title']=book_title.text.replace('\\n','').strip()\n",
        "        else:\n",
        "            book['book_title']=''\n",
        "        \n",
        "        print(i, book['book_title'])\n",
        "\n",
        "        #Author(s) of the book\n",
        "        book['book_authors']='|'.join([a.find('span', attrs={'itemprop':'name'}).text for a in book_soup.find_all('a', attrs={'class':'authorName'})])\n",
        "        \n",
        "        #Rating given by users on goodreads\n",
        "        book_rating=book_soup.find('span', attrs={'itemprop':'ratingValue'})\n",
        "        if book_rating:\n",
        "            book['book_rating']=book_rating.text.replace('\\n','').strip()\n",
        "        else:\n",
        "            book['book_rating']=''\n",
        "        book['book_rating_count']=book_soup.find('meta', attrs={'itemprop':'ratingCount'})['content']\n",
        "\n",
        "        #No. of reviews for the book\n",
        "        book['book_review_count']=book_soup.find('meta', attrs={'itemprop':'reviewCount'})['content']\n",
        "\n",
        "        #A short description of the book, usually found on the back or inside cover of the book. Also called a blurb\n",
        "        book_desc=book_soup.find('div', attrs={'class':'readable stacked'})\n",
        "        if book_desc:\n",
        "            book['book_desc']=book_desc.find_all('span')[-1].text\n",
        "        else:\n",
        "            book['book_desc']=''\n",
        "\n",
        "        #Format of the book, e.g, paperback, hardcover, Kindle edition, etc.\n",
        "        book_format=book_soup.find('div', attrs={'id':'details'}).find('span', attrs={'itemprop':'bookFormat'})\n",
        "        if book_format:\n",
        "            book['book_format']=book_format.text\n",
        "        else:\n",
        "            book['book_format']=''\n",
        "        \n",
        "        #Edition of the book\n",
        "        book_edition=book_soup.find('div', attrs={'id':'details'}).find('span', attrs={'itemprop':'bookEdition'})\n",
        "        if book_edition:\n",
        "            book['book_edition']=book_edition.text\n",
        "        else:\n",
        "            book['book_edition']=''\n",
        "\n",
        "        #No. of pages in the book\n",
        "        book_pages=book_soup.find('div', attrs={'id':'details'}).find('span', attrs={'itemprop':'numberOfPages'})\n",
        "        if book_pages:\n",
        "            book['book_pages']=book_pages.text\n",
        "        else:\n",
        "            book['book_pages']=''\n",
        "        \n",
        "        #ISBN code of the book\n",
        "        book_isbn=book_soup.find('div', attrs={'id':'bookDataBox'}).find('span', attrs={'itemprop':'isbn'})\n",
        "        if book_isbn:\n",
        "            book['book_isbn']=book_isbn.text\n",
        "        else:\n",
        "            book['book_isbn']=''\n",
        "\n",
        "        #List of genres that the book belongs to. User supplied data.\n",
        "        genres_list=book_soup.find_all('a', attrs={'class':'actionLinkLite bookPageGenreLink'})\n",
        "        book['genres']='|'.join([i.text for i in genres_list])\n",
        "        book_rows.append(book)\n",
        "\n",
        "        if i%save_every==0:\n",
        "            book_data.append(pd.DataFrame.from_dict(book_rows)).to_csv('book_data.csv', index=False)\n",
        "            book_rows=[]\n",
        "    except:\n",
        "        book_data.append(pd.DataFrame.from_dict(book_rows)).to_csv('book_data.csv', index=False)\n",
        "        book_rows=[]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OGF5v9eyO0r"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "\n",
        "def genre_count(genres):\n",
        "    '''\n",
        "    Returns the number of genres in the genre column of the dataframe\n",
        "    Input: genre data\n",
        "    Output: no. of genres\n",
        "    '''\n",
        "    try:\n",
        "        return len(genres.split('|'))\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "\n",
        "book_data_train['num_genres'] = book_data_train['genres'].apply(genre_count)\n",
        "book_data_train['num_genres'].iplot(kind='histogram', xTitle='No. of genres', yTitle='Count', gridcolor='rgba(0,0,0,0)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXubTbOPyRyI"
      },
      "source": [
        "genre_counts=defaultdict(int)\n",
        "for i in book_data_train.index:\n",
        "    g=book_data_train.at[i, 'genres']\n",
        "    if type(g)==str:\n",
        "        for j in g.split('|'):\n",
        "            genre_counts[j]+=1\n",
        "\n",
        "print(len(genre_counts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5I6iWgHyUWk"
      },
      "source": [
        "\n",
        "configure_plotly_browser_state()\n",
        "genre_counts_df=pd.DataFrame.from_records(sorted(genre_counts.items(), key=lambda x:x[1], reverse=True), columns=['genre', 'count'])\n",
        "genre_counts_df[:50].iplot(\n",
        "    kind='bar', \n",
        "    x='genre', \n",
        "    y='count',\n",
        "    margin={\n",
        "        'b':175\n",
        "    },\n",
        "    gridcolor='rgba(0,0,0,0)'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a0bn6OSyXW7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from os.path import exists\n",
        "\n",
        "def plot_book_covers(n):\n",
        "    '''\n",
        "    Prints a specified no. of book covers and their corresponding genres. Helps to examine if there is any pattern in the book covers\n",
        "    Input: no. of book covers to display\n",
        "    Output: None\n",
        "    '''\n",
        "    indices=list(np.random.randint(min(book_data_train.index), max(book_data_train.index), size=n))\n",
        "    fig=plt.figure(figsize=(n*5, 10))\n",
        "    for i in indices:\n",
        "        if exists(f'train/images/{i}.jpg'):\n",
        "            ax = fig.add_subplot(2, n, (indices.index(i)+1), xticks=[], yticks=[])\n",
        "            ax.imshow(Image.open(f'train/images/{i}.jpg'))\n",
        "            ax = fig.add_subplot(2, n, (indices.index(i)+1)+n, xticks=[], yticks=[])\n",
        "            if type(book_data_train.at[i, 'genres'])==str:\n",
        "                t='\\n'.join(book_data_train.at[i, 'genres'].split('|'))\n",
        "            else:\n",
        "                t=''\n",
        "            ax.text(0.5, 0.5, t, fontsize=15, horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWRyX0_xydDP"
      },
      "source": [
        "book_data_train['num_authors']=book_data_train['book_authors'].str.split('|').apply(len)\n",
        "configure_plotly_browser_state()\n",
        "book_data_train['num_authors'].iplot(kind='histogram', xTitle='No. of authors', yTitle='Count', gridcolor='rgba(0,0,0,0)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gEF66gtyfR1"
      },
      "source": [
        "book_data_train[book_data_train['num_authors']>10].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZxhxiUTyiGk"
      },
      "source": [
        "def remove_invalid(df):\n",
        "    '''\n",
        "    Removes records that have invalid descriptions from the dataframe\n",
        "    Input: dataframe\n",
        "    Output: Cleaned up dataframe\n",
        "    '''\n",
        "    invalid_desc_idxs=[]\n",
        "    for i in df.index:\n",
        "        try:\n",
        "            a=detect(df.at[i,'book_desc'])\n",
        "        except:\n",
        "            invalid_desc_idxs.append(i)\n",
        "    \n",
        "    df=df.drop(index=invalid_desc_idxs)\n",
        "    return df\n",
        "\n",
        "book_data_train=remove_invalid(book_data_train)\n",
        "book_data_train['lang']=book_data_train.book_desc.apply(detect)\n",
        "\n",
        "#Downloading the list of languages to map the two-letter lang code to the language name\n",
        "lang_lookup=pd.read_html('https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes')[1]\n",
        "lang_lookup.drop(columns=[0], inplace=True)\n",
        "lang_lookup.columns=lang_lookup.iloc[0]\n",
        "lang_lookup=lang_lookup.reindex(lang_lookup.index.drop(0))\n",
        "lang_lookup.rename(columns={'639-1': 'lang'}, inplace=True)\n",
        "\n",
        "def get_language(lang):\n",
        "    if lang in list(lang_lookup['lang']):\n",
        "        return lang_lookup[lang_lookup['lang']==lang]['ISO language name'].values[0]\n",
        "    else:\n",
        "        return 'N/A'\n",
        "\n",
        "book_data_train['language']=book_data_train['lang'].apply(get_language)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdFhiva6yk1N"
      },
      "source": [
        "configure_plotly_browser_state()\n",
        "group_by_lang=book_data_train.groupby(['language'])['book_title'].count().reset_index().sort_values(by=['book_title'], ascending=False)\n",
        "group_by_lang.iplot(\n",
        "    kind='bar', \n",
        "    x='language', \n",
        "    y='book_title',\n",
        "    margin={\n",
        "        'b':200\n",
        "    },\n",
        "    gridcolor='rgba(0,0,0,0)'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8_EjGNDynuH"
      },
      "source": [
        "book_data_train[book_data_train['language']=='Tamil']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULYt9mt8yynB"
      },
      "source": [
        "!pip install langdetect -q\n",
        "from langdetect import detect\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import LSTM\n",
        "\n",
        "import string\n",
        "valid_chars=string.ascii_letters+string.digits+' '\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import cufflinks as cf\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "def configure_plotly_browser_state():\n",
        "    #This function is required to see Plotly charts in colab. Call this function in every cell where a Plotly chart gets drawn.\n",
        "    import IPython\n",
        "    display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-1.43.1.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANVhnvaBy5ZT"
      },
      "source": [
        "def genre_binarizer(genres):\n",
        "    '''\n",
        "    Analyzes the genres string passed as argument to check if fiction or nonfiction is present and returns a genre appropriately\n",
        "    Inputs: the genres column data from the book data frame\n",
        "    Returns:\n",
        "    - fiction, if fiction is present\n",
        "    - nonfiction, if nonfiction is present\n",
        "    - neither, if neither is present\n",
        "    '''\n",
        "    genre_list=genres.lower().split('|')\n",
        "    if 'fiction' in genre_list:\n",
        "        return 'fiction'\n",
        "    elif 'nonfiction' in genre_list:\n",
        "        return 'nonfiction'\n",
        "    else:\n",
        "        return 'neither'\n",
        "\n",
        "def eng_desc(df):\n",
        "    '''\n",
        "    Analyzes the book description in the data frame passed, and returns a data frame with non-English records removed using the langdetect package\n",
        "    Inputs: data frame\n",
        "    Returns: data frame with non-English description records removed\n",
        "    '''\n",
        "    invalid_desc_idxs=[]\n",
        "    for i in df.index:\n",
        "        try:\n",
        "            a=detect(df.at[i,'book_desc'])\n",
        "        except:\n",
        "            invalid_desc_idxs.append(i)\n",
        "    \n",
        "    print('Removing these records as the descriptions are invalid:',invalid_desc_idxs)\n",
        "    df=df.drop(index=invalid_desc_idxs)\n",
        "    df['lang']=df.book_desc.apply(detect)\n",
        "    df=df[df.lang=='en']\n",
        "    return df\n",
        "\n",
        "def add_space_case(desc):\n",
        "    '''\n",
        "    Analyzes the book description passed and inserts spaces where a lowercase letter is followed immediately by an uppercase letter.\n",
        "    Inputs: book description\n",
        "    Returns: Modified book description'''\n",
        "    upd_desc=''\n",
        "    \n",
        "    for i in range(len(desc)-1):\n",
        "        upd_desc+=desc[i]\n",
        "        if desc[i] in string.ascii_lowercase and desc[i+1] in string.ascii_uppercase:\n",
        "            upd_desc+=' '\n",
        "    \n",
        "    upd_desc+=desc[-1]\n",
        "    return upd_desc  \n",
        "\n",
        "def remove_punctuation(desc):\n",
        "    '''\n",
        "    Modifies the book description passed to \n",
        "    - insert spaces in place of punctuations\n",
        "    - join apostrophe words to their parent words and \n",
        "    - insert spaces where lowercase is followed by uppercase\n",
        "    Inputs: book description\n",
        "    Returns: modified book description\n",
        "    '''\n",
        "    desc=add_space_case(desc)\n",
        "    apostrophe_words=['m', 're', 've', 'll', 't', 's', 'd']\n",
        "    \n",
        "    desc=desc.lower()\n",
        "        \n",
        "    desc=''.join([c if c in valid_chars else ' ' for c in desc])\n",
        "    \n",
        "    for a in apostrophe_words:\n",
        "        desc=desc.replace(' '+a+' ', a+' ')\n",
        "\n",
        "    return desc\n",
        "\n",
        "        \n",
        "def df_cleaner(df):\n",
        "    '''\n",
        "    Takes in a dataframe and performs the following steps to clean up:\n",
        "    - Removes records with null genres and descriptions\n",
        "    - Removes records where genre is neither fiction nor nonfiction\n",
        "    - Removes records where the description is non-English\n",
        "    - Removes punctuations from the description\n",
        "    - Resets the index\n",
        "    Inputs: dataframe Returns: cleaned-up dataframe\n",
        "    '''\n",
        "    print(\"No. of records            :\", len(df))\n",
        "    \n",
        "    df=df[df.genres.notnull()]\n",
        "    print(\"After removing null genres:\", len(df))\n",
        "    \n",
        "    df=df[df.book_desc.notnull()]\n",
        "    print(\"After removing null descs :\", len(df))\n",
        "    \n",
        "    df=df[df.book_desc.str.strip().apply(len)>0]\n",
        "    print(\"After removing zero descs :\", len(df))\n",
        "    \n",
        "    df['binary_genre']=df.genres.apply(genre_binarizer)\n",
        "    df=df[df.binary_genre!='neither']\n",
        "    print(\"Only fiction or nonfiction:\", len(df))\n",
        "    \n",
        "    df=eng_desc(df)\n",
        "    print(\"After removing non-English:\", len(df))\n",
        "    \n",
        "    df['clean_desc']=df.book_desc.apply(remove_punctuation)\n",
        "    \n",
        "    df.reset_index(drop=True, inplace=True)\n",
        "    print('---------------------------')\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYnQ01wwzDYg"
      },
      "source": [
        "#Calculating the no. of words in the book descriptions and storing them in a dataframe - this enables the use of cufflinks\n",
        "len_df=pd.DataFrame()\n",
        "desc_lengths=[len(i.split()) for i in book_data_train.clean_desc] + [len(i.split()) for i in book_data_test.clean_desc]\n",
        "len_df['desc_lengths']=desc_lengths\n",
        "\n",
        "cf.go_offline()\n",
        "\n",
        "#This function needs to be called to draw Plotly charts in Colab\n",
        "configure_plotly_browser_state()\n",
        "\n",
        "\n",
        "#Binning the lengths (no. of words) and calculating a cumsum to figure the 80% mark\n",
        "len_df_bins=len_df.desc_lengths.value_counts(bins=100, normalize=True).reset_index().sort_values(by=['index'])\n",
        "len_df_bins['cumulative']=len_df_bins.desc_lengths.cumsum()\n",
        "len_df_bins['index']=len_df_bins['index'].astype('str')\n",
        "len_df_bins.iplot(kind='bar', x='index', y='cumulative')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQsNRTS6zG0D"
      },
      "source": [
        "vocabulary=set() #unique list of all words\n",
        "\n",
        "def add_to_vocab(df, vocabulary):\n",
        "    for i in df.clean_desc:\n",
        "        for word in i.split():\n",
        "            vocabulary.add(word)\n",
        "    return vocabulary\n",
        "\n",
        "vocabulary=add_to_vocab(book_data_train, vocabulary)\n",
        "vocabulary=add_to_vocab(book_data_test, vocabulary)\n",
        "\n",
        "#This dictionary represents the mapping from word to token. Using token+1 to skip 0, since 0 will be used for padding descriptions with less than 200 words\n",
        "vocab_dict={word: token+1 for token, word in enumerate(list(vocabulary))}\n",
        "\n",
        "#This dictionary represents the mapping from token to word\n",
        "token_dict={token+1: word for token, word in enumerate(list(vocabulary))}\n",
        "\n",
        "assert token_dict[1]==token_dict[vocab_dict[token_dict[1]]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4suSfHnzJbH"
      },
      "source": [
        "def tokenizer(desc, vocab_dict, max_desc_length):\n",
        "    '''\n",
        "    Function to tokenize descriptions\n",
        "    Inputs:\n",
        "    - desc, description\n",
        "    - vocab_dict, dictionary mapping words to their corresponding tokens\n",
        "    - max_desc_length, used for pre-padding the descriptions where the no. of words is less than this number\n",
        "    Returns:\n",
        "    List of length max_desc_length, pre-padded with zeroes if the desc length was less than max_desc_length\n",
        "    '''\n",
        "    a=[vocab_dict[i] if i in vocab_dict else 0 for i in desc.split()]\n",
        "    b=[0] * max_desc_length\n",
        "    if len(a)<max_desc_length:\n",
        "        return np.asarray(b[:max_desc_length-len(a)]+a).squeeze()\n",
        "    else:\n",
        "        return np.asarray(a[:max_desc_length]).squeeze()\n",
        "\n",
        "book_data_train['desc_tokens']=book_data_train.clean_desc.apply(tokenizer, args=(vocab_dict, max_desc_length))\n",
        "book_data_test['desc_tokens']=book_data_test.clean_desc.apply(tokenizer, args=(vocab_dict, max_desc_length))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us36_KxNzN84"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(vocabulary)+1, output_dim=200, input_length=max_desc_length))\n",
        "model.add(LSTM(200, return_sequences=True))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(200))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.fit(x_train, \n",
        "          y_train,\n",
        "          validation_data=(x_val, y_val),\n",
        "          batch_size=128, \n",
        "          epochs=2)\n",
        "score = model.evaluate(x_test, y_test, batch_size=16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kPhE86AzQ-X"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "\n",
        "from requests import get\n",
        "\n",
        "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "         'Referer': 'https://cssspritegenerator.com',\n",
        "         'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "         'Accept-Encoding': 'none',\n",
        "         'Accept-Language': 'en-US,en;q=0.8'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REsSTbEzzTaN"
      },
      "source": [
        "book_page=get(test_url)\n",
        "book_soup=BeautifulSoup(book_page.content, 'html.parser')\n",
        "\n",
        "book_desc=book_soup.find('div', attrs={'class':'readable stacked'})\n",
        "if book_desc:\n",
        "    test_string=book_desc.find_all('span')[-1].text\n",
        "else:\n",
        "    test_string=''\n",
        "\n",
        "if test_string=='':\n",
        "    print('Cannot read book description from web page')\n",
        "else:\n",
        "    a=tokenizer(remove_punctuation(test_string), vocab_dict, max_desc_length)\n",
        "    a=np.reshape(a, (1,max_desc_length))\n",
        "    \n",
        "    output=model.predict(a, batch_size=1)\n",
        "\n",
        "    #test_h = tuple([each.data for each in test_h])\n",
        "\n",
        "    #output, _ = model(a, test_h)\n",
        "\n",
        "    pred = np.asscalar((output>0.5)*1)\n",
        "\n",
        "    print(classes[pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAi4wogxyD0J"
      },
      "source": [
        "import pandas as pd\n",
        "import wget\n",
        "import os\n",
        "\n",
        "book_data=pd.read_csv('book_data.csv')\n",
        "PATH='C:\\\\Python\\\\Python37-32\\\\Scripts\\\\code\\\\images\\\\'\n",
        "files=os.listdir(PATH)\n",
        "n=0\n",
        "if len(files)>0:\n",
        "    n=max([int(f[:-4]) for f in os.listdir(PATH)])+1\n",
        "\n",
        "for i in range(n, len(book_data)):\n",
        "    url=book_data.at[i, 'image_url']\n",
        "    filename=f'{i}.jpg'\n",
        "    if not pd.isna(url):\n",
        "        wget.download(url, PATH+filename)\n",
        "    if i%100==0:\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}