{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Helper functions.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAvUGKQTyB5U",
        "outputId": "376f0d59-e288-4e90-ef1a-ec04a2df42e1"
      },
      "source": [
        "#URL COLLECTOR\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "from requests import get\n",
        "\n",
        "#Sometimes not including the header results in a failed response\n",
        "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "         'Referer': 'https://cssspritegenerator.com',\n",
        "         'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "         'Accept-Encoding': 'none',\n",
        "         'Accept-Language': 'en-US,en;q=0.8'}\n",
        "\n",
        "BASE_URL='https://www.goodreads.com'\n",
        "LIST_URL='https://www.goodreads.com/list/show/1.Best_Books_Ever'\n",
        "#LIST_URL='https://www.goodreads.com/list/best_of_year/2018?id=119307.Best_books_of_2018'\n",
        "\n",
        "books={'URL':[]}\n",
        "\n",
        "#the no. of pages this list has\n",
        "num_pages=557\n",
        "\n",
        "for i in range(1, num_pages):\n",
        "  #time.sleep(120) #make sure you give enough time between page loads to not avoid server overload\n",
        "  print(f'Reading page {i}')\n",
        "  list_page_url=f'{LIST_URL}&page={i}'\n",
        "  list_page=get(list_page_url, headers=hdr)\n",
        "  list_soup = BeautifulSoup(list_page.content, 'html.parser')\n",
        "  book_table=list_soup.find('table', attrs={'class':'tableList js-dataTooltip'})\n",
        "  rows=book_table.find_all('tr')\n",
        "  books['URL']+=[BASE_URL+r.find('a', attrs={'class':'bookTitle'}).attrs['href'] for r in rows]\n",
        "\n",
        "books_df=pd.DataFrame.from_dict(books)\n",
        "books_df.to_csv('books.csv')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading page 1\n",
            "Reading page 2\n",
            "Reading page 3\n",
            "Reading page 4\n",
            "Reading page 5\n",
            "Reading page 6\n",
            "Reading page 7\n",
            "Reading page 8\n",
            "Reading page 9\n",
            "Reading page 10\n",
            "Reading page 11\n",
            "Reading page 12\n",
            "Reading page 13\n",
            "Reading page 14\n",
            "Reading page 15\n",
            "Reading page 16\n",
            "Reading page 17\n",
            "Reading page 18\n",
            "Reading page 19\n",
            "Reading page 20\n",
            "Reading page 21\n",
            "Reading page 22\n",
            "Reading page 23\n",
            "Reading page 24\n",
            "Reading page 25\n",
            "Reading page 26\n",
            "Reading page 27\n",
            "Reading page 28\n",
            "Reading page 29\n",
            "Reading page 30\n",
            "Reading page 31\n",
            "Reading page 32\n",
            "Reading page 33\n",
            "Reading page 34\n",
            "Reading page 35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mdJHEoHyKVn"
      },
      "source": [
        "#DATA COLLECTOR\n",
        "from bs4 import BeautifulSoup\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "\n",
        "from requests import get\n",
        "\n",
        "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "         'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "         'Referer': 'https://cssspritegenerator.com',\n",
        "         'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "         'Accept-Encoding': 'none',\n",
        "         'Accept-Language': 'en-US,en;q=0.8'}\n",
        "\n",
        "if not os.path.exists('book_data.csv'):\n",
        "  book_data=pd.DataFrame(columns=[\n",
        "    'image_url',\n",
        "    'book_title',\n",
        "    'book_authors',\n",
        "    'book_rating',\n",
        "    'book_rating_count',\n",
        "    'book_review_count',\n",
        "    'book_desc',\n",
        "    'book_format',\n",
        "    'book_edition',\n",
        "    'book_pages',\n",
        "    'book_isbn',\n",
        "    'genres'\n",
        "  ])\n",
        "\n",
        "  book_data.to_csv('book_data.csv')\n",
        "\n",
        "books=pd.read_csv('books.csv')\n",
        "book_data=pd.read_csv('book_data.csv')\n",
        "\n",
        "book_rows=[]\n",
        "save_every=10\n",
        "\n",
        "for i in range(len(book_data), len(books)):\n",
        "    time.sleep(60)\n",
        "    try:\n",
        "        book_URL=books.at[i, 'URL']\n",
        "        book_page=get(book_URL)\n",
        "        book_soup=BeautifulSoup(book_page.content, 'html.parser')\n",
        "\n",
        "        book=dict()\n",
        "\n",
        "        #Save the URL of the image of the book cover to be downloaded later\n",
        "        image_url=book_soup.find('img', attrs={'id':'coverImage'})\n",
        "        if image_url:\n",
        "            book['image_url']=image_url.attrs['src']\n",
        "        else:\n",
        "            book['image_url']=''\n",
        "\n",
        "        #Title of the book\n",
        "        book_title=book_soup.find('h1', attrs={'id':'bookTitle'})\n",
        "        if book_title:\n",
        "            book['book_title']=book_title.text.replace('\\n','').strip()\n",
        "        else:\n",
        "            book['book_title']=''\n",
        "        \n",
        "        print(i, book['book_title'])\n",
        "\n",
        "        #Author(s) of the book\n",
        "        book['book_authors']='|'.join([a.find('span', attrs={'itemprop':'name'}).text for a in book_soup.find_all('a', attrs={'class':'authorName'})])\n",
        "        \n",
        "        #Rating given by users on goodreads\n",
        "        book_rating=book_soup.find('span', attrs={'itemprop':'ratingValue'})\n",
        "        if book_rating:\n",
        "            book['book_rating']=book_rating.text.replace('\\n','').strip()\n",
        "        else:\n",
        "            book['book_rating']=''\n",
        "        book['book_rating_count']=book_soup.find('meta', attrs={'itemprop':'ratingCount'})['content']\n",
        "\n",
        "        #No. of reviews for the book\n",
        "        book['book_review_count']=book_soup.find('meta', attrs={'itemprop':'reviewCount'})['content']\n",
        "\n",
        "        #A short description of the book, usually found on the back or inside cover of the book. Also called a blurb\n",
        "        book_desc=book_soup.find('div', attrs={'class':'readable stacked'})\n",
        "        if book_desc:\n",
        "            book['book_desc']=book_desc.find_all('span')[-1].text\n",
        "        else:\n",
        "            book['book_desc']=''\n",
        "\n",
        "        #Format of the book, e.g, paperback, hardcover, Kindle edition, etc.\n",
        "        book_format=book_soup.find('div', attrs={'id':'details'}).find('span', attrs={'itemprop':'bookFormat'})\n",
        "        if book_format:\n",
        "            book['book_format']=book_format.text\n",
        "        else:\n",
        "            book['book_format']=''\n",
        "        \n",
        "        #Edition of the book\n",
        "        book_edition=book_soup.find('div', attrs={'id':'details'}).find('span', attrs={'itemprop':'bookEdition'})\n",
        "        if book_edition:\n",
        "            book['book_edition']=book_edition.text\n",
        "        else:\n",
        "            book['book_edition']=''\n",
        "\n",
        "        #No. of pages in the book\n",
        "        book_pages=book_soup.find('div', attrs={'id':'details'}).find('span', attrs={'itemprop':'numberOfPages'})\n",
        "        if book_pages:\n",
        "            book['book_pages']=book_pages.text\n",
        "        else:\n",
        "            book['book_pages']=''\n",
        "        \n",
        "        #ISBN code of the book\n",
        "        book_isbn=book_soup.find('div', attrs={'id':'bookDataBox'}).find('span', attrs={'itemprop':'isbn'})\n",
        "        if book_isbn:\n",
        "            book['book_isbn']=book_isbn.text\n",
        "        else:\n",
        "            book['book_isbn']=''\n",
        "\n",
        "        #List of genres that the book belongs to. User supplied data.\n",
        "        genres_list=book_soup.find_all('a', attrs={'class':'actionLinkLite bookPageGenreLink'})\n",
        "        book['genres']='|'.join([i.text for i in genres_list])\n",
        "        book_rows.append(book)\n",
        "\n",
        "        if i%save_every==0:\n",
        "            book_data.append(pd.DataFrame.from_dict(book_rows)).to_csv('book_data.csv', index=False)\n",
        "            book_rows=[]\n",
        "    except:\n",
        "        book_data.append(pd.DataFrame.from_dict(book_rows)).to_csv('book_data.csv', index=False)\n",
        "        book_rows=[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmoGc-8kyeCr"
      },
      "source": [
        "#IMAGE COLLECTOR\n",
        "import pandas as pd\n",
        "import wget\n",
        "import os\n",
        "\n",
        "book_data=pd.read_csv('book_data.csv')\n",
        "PATH='C:\\\\Python\\\\Python37-32\\\\Scripts\\\\code\\\\images\\\\'\n",
        "files=os.listdir(PATH)\n",
        "n=0\n",
        "if len(files)>0:\n",
        "    n=max([int(f[:-4]) for f in os.listdir(PATH)])+1\n",
        "\n",
        "for i in range(n, len(book_data)):\n",
        "    url=book_data.at[i, 'image_url']\n",
        "    filename=f'{i}.jpg'\n",
        "    if not pd.isna(url):\n",
        "        wget.download(url, PATH+filename)\n",
        "    if i%100==0:\n",
        "        print(i)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}